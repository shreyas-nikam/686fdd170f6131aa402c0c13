# TalentMine Lab Project: HR Document Table Extractor

## Project Description

This Streamlit application serves as a lab project simulating the core functionality of the **TalentMine** system's 'Offline Preprocessing' [1, Algorithm 1]. Its primary purpose is to demonstrate how Large Language Models (LLMs) can effectively extract and semantically enrich tabular data from complex HR documents. The application highlights the limitations of traditional Optical Character Recognition (OCR) methods when dealing with the nuanced structures and formatting common in HR documents like benefits matrices and compensation data, showcasing the improved performance of LLM-based approaches [1, Abstract, Section 2].

The application aims to provide users, particularly those interested in Document AI, LLMs, and HR technology, with an intuitive understanding of the challenges and solutions in extracting valuable information from unstructured or semi-structured HR documents. By allowing users to simulate extractions and view performance metrics, it illustrates the business value of leveraging LLMs for improved data accuracy, efficiency, and compliance in HR operations.

**Business Value:**
Showcases how LLMs can dramatically improve the accuracy and efficiency of tabular data extraction from complex HR documents, leading to better decision-making, improved compliance, and reduced operational costs compared to traditional methods.

**Target Audience:**
Data scientists, HR professionals, LLM practitioners, and students interested in Document AI and Retrieval-Augmented Generation (RAG) systems.

**Learning Outcomes:**
- Understand key insights from HR documents and supporting data.
- Comprehend the limitations of traditional table extraction for HR documents.
- Learn how LLMs semantically enrich tabular data, preserving context.
- Evaluate the impact of different simulated LLM models on extraction accuracy.

## Features

The application simulates key aspects of the TalentMine system's extraction process, offering the following features:

*   **Synthetic Document Selection**: Users can choose from a predefined set of synthetic HR document types (e.g., Benefits Plan, Compensation Matrix) to mimic diverse formats and layouts [1, Section 2.1].
*   **Simulated Extraction Process**: The application demonstrates a simplified multi-step extraction simulation:
    *   **Raw OCR Output**: Shows the potentially poorly structured text typically resulting from traditional OCR.
    *   **LLM-Enhanced Semantic Output**: Presents the semantically enriched, contextually aware text generated by a 'simulated LLM', preserving 'row-column relationships' and 'contextual dependencies' [1, Section E].
*   **Performance Comparison**: Displays simulated accuracy and information not found rates for various 'extraction methods' (e.g., 'TalentMine LLM', 'AWS Textract', 'AWS Textract Visual Q&A') based on conceptual data derived from research performance metrics [1, Table 2, Table 3]. *Note: Metrics are currently fully simulated based on paper concepts for the 'Benefits Plan' document type.*
*   **Interactive Parameters**: Allows users to select 'Document Type' and 'Simulated Extraction Method' to observe conceptual differences in extraction behavior and simulated performance.
*   **Visualizations**: Provides side-by-side comparisons of simulated outputs and bar charts for comparing simulated performance metrics across different methods.

## Getting Started

Follow these instructions to get the application up and running on your local machine.

### Prerequisites

*   Python 3.7 or higher
*   `pip` (Python package installer)
*   `git` (for cloning the repository)

### Installation

1.  **Clone the repository:**
    ```bash
    git clone <repository_url> # Replace <repository_url> with the actual URL
    cd <repository_directory>
    ```

2.  **Create a virtual environment** (recommended):
    ```bash
    python -m venv .venv
    ```

3.  **Activate the virtual environment:**
    *   On macOS and Linux:
        ```bash
        source .venv/bin/activate
        ```
    *   On Windows:
        ```bash
        .venv\Scripts\activate
        ```

4.  **Install the required packages:**
    Create a `requirements.txt` file in the root directory of the project with the following content:
    ```
    streamlit>=1.0
    pandas>=1.0
    plotly>=5.0
    ```
    Then, install the packages:
    ```bash
    pip install -r requirements.txt
    ```

## Usage

1.  **Run the Streamlit application:**
    Make sure your virtual environment is activated.
    ```bash
    streamlit run app.py
    ```

2.  **Access the Application:**
    Your default web browser should open automatically to the Streamlit application interface (usually at `http://localhost:8501`). If not, open your browser and navigate to that address.

3.  **Navigate the Application:**
    Use the sidebar navigation menu on the left to interact with the application:
    *   **Document & Method Selection**: Choose the synthetic document type and the simulated extraction method.
    *   **Extraction Output**: View the simulated raw OCR output and the LLM-enhanced output, along with a comparison.
    *   **Performance Metrics**: See the simulated accuracy and information not found rates for various methods via a table and charts.

## Project Structure

The project is organized as follows:

```
.
├── app.py
├── requirements.txt
└── application_pages/
    ├── __init__.py     # Required to treat 'application_pages' as a Python package
    ├── page1.py        # Handles document/method selection and synthetic data loading
    ├── page2.py        # Handles simulated extraction and output display
    └── page3.py        # Handles simulated metric calculation and visualization
```

*   `app.py`: The main entry point of the Streamlit application, handling navigation and overall structure.
*   `requirements.txt`: Lists the necessary Python libraries.
*   `application_pages/`: A directory containing separate Python modules for each major section or "page" of the Streamlit app, improving organization.

## Technology Stack

*   **Framework**: Streamlit
*   **Language**: Python
*   **Data Manipulation**: Pandas
*   **Visualization**: Plotly
*   **Concepts Simulated**: LLMs (Claude v3 Haiku, etc.), Traditional OCR, AWS Textract, AWS Textract Visual Q&A, HR Documents, Tabular Data Extraction.

## Contributing

This project is primarily intended as a demonstration and lab exercise. Contributions are not actively sought at this time. However, you are welcome to fork the repository and experiment with the code for educational purposes.

## License

This lab project is provided for **educational purposes only**.

```markdown
© QuantUniversity 2025

This notebook was created for **educational purposes only** and is **not intended for commercial use**.
- You **may not copy, share, or redistribute** this notebook **without explicit permission** from QuantUniversity.
- You **may not delete or modify this license cell** without authorization.
- This notebook was generated using **QuCreate**, an AI-powered assistant.
- Content generated by AI may contain **hallucinated or incorrect information**. Please **verify before using**.

All rights reserved. For permissions or commercial licensing, contact: [info@quantuniversity.com](mailto:info@quantuniversity.com)
```

Please refer to the license notice within the application (`app.py` and `page3.py`) for the full terms.

## Contact

For inquiries regarding this project, licensing, or QuantUniversity's offerings, please contact:

Email: info@quantuniversity.com

---
**Reference:**

[1] Varun Mannam et al., 'TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables,' arXiv preprint arXiv:2507.00041v1, 2025. (Note: This reference is cited as per the application code and represents a hypothetical future publication).
