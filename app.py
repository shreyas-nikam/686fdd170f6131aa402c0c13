
import streamlit as st
st.set_page_config(page_title="TalentMine", layout="wide")
st.sidebar.image("https://www.quantuniversity.com/assets/img/logo5.jpg")
st.sidebar.divider()
st.title("TalentMine")
st.divider()
st.markdown("""
# HR Document Table Extractor

### Overview
This application simulates the core functionality of the TalentMine system's 'Offline Preprocessing' [1, Algorithm 1] by demonstrating how LLMs extract and semantically enrich tabular data from HR documents. It highlights the challenges of traditional OCR methods versus the improved performance of LLM-based approaches, particularly for complex HR tables like benefits matrices and compensation data [1, Abstract, Section 2].

#### Business Value
The business value of this application lies in showcasing how LLMs can significantly improve the accuracy and efficiency of extracting tabular data from HR documents. Traditional OCR methods often struggle with the complex layouts and formatting of these documents, leading to data loss and errors. This application demonstrates how LLMs can overcome these challenges by semantically enriching the extracted data, preserving context and relationships. This improved data extraction can lead to better decision-making, improved compliance, and reduced costs in HR operations.

#### Target Audience
Data scientists, HR professionals, LLM practitioners, and students interested in Document AI and Retrieval-Augmented Generation (RAG) systems.

#### Learning Outcomes
- Understand the key insights contained in the uploaded document and supporting data.
- Comprehend the limitations of traditional table extraction methods for HR documents.
- Learn how LLMs can semantically enrich tabular data, preserving context and relationships.
- Evaluate the impact of different simulated LLM models on extraction accuracy.

#### Features
- **Synthetic Document Upload**: Users can 'upload' (select from a predefined synthetic dataset) images of various HR documents containing tables, such as benefits enrollment forms or compensation matrices, to mimic diverse formats and complex layouts common in HR [1, Section 2.1].
- **Simulated Extraction Process**: The application will simulate the multi-step extraction process described in TalentMine, showing:
    - **Raw OCR Output**: The initial, often poorly structured text that would result from traditional OCR methods.
    - **LLM-Enhanced Semantic Output**: The semantically enriched, contextually meaningful text generated by a 'simulated LLM' (like Claude v3 Haiku). This demonstrates the preservation of 'row-column relationships' and 'contextual dependencies' as described in the system prompt [1, Section E].
- **Performance Comparison**: Display simulated accuracy metrics for different 'extraction methods' (e.g., 'TalentMine LLM', 'AWS Textract', 'AWS Textract Visual Q&A') based on performance data provided in the document [1, Table 2, Table 3].
- **Interactive Parameters**: Sliders or dropdowns to adjust 'document complexity' (e.g., simple table vs. hierarchical) and select 'simulated LLM model' to observe how extraction performance changes based on the document's comparative analysis [1, Section 4.4].

#### How It Explains the Concept
This lab directly illustrates the 'semantic information loss' in current table extraction pipelines and how TalentMine's 'novel LLM-based method for semantically enriched table representation' overcomes these challenges [1, Section 1]. By comparing outputs and simulated metrics, users gain an intuitive understanding of the benefits of LLM-based document processing for HR operations.

#### Visuals
- Side-by-side comparison of the original table image, raw OCR text, and LLM-processed structured text.
- Bar charts comparing simulated 'Accuracy' and 'Information Not Found' rates for different extraction methods and simulated LLM models [1, Table 2, Table 3].

#### Parameters
- `Document Type`: Dropdown (e.g., 'Benefits Plan', 'Compensation Matrix', 'Performance Review').
- `Simulated Extraction Method`: Dropdown (e.g., 'TalentMine (Claude v3 Haiku)', 'AWS Textract', 'AWS Textract Visual Q&A').

#### References:
[1] Varun Mannam et al., 'TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables,' arXiv preprint arXiv:2507.00041v1, 2025.
""")
# Your code starts here
page = st.sidebar.selectbox(label="Navigation", options=["Document & Method Selection", "Extraction Output", "Performance Metrics"])
if page == "Document & Method Selection":
    from application_pages.page1 import run_page1
    run_page1()
elif page == "Extraction Output":
    from application_pages.page2 import run_page2
    run_page2()
elif page == "Performance Metrics":
    from application_pages.page3 import run_page3
    run_page3()
# Your code ends
st.divider()
st.write("© 2025 QuantUniversity. All Rights Reserved.")
st.caption("The purpose of this demonstration is solely for educational use and illustration. "
            "Any reproduction of this demonstration "
            "requires prior written consent from QuantUniversity. "
            "This lab was generated using the QuCreate platform. QuCreate relies on AI models for generating code, which may contain inaccuracies or errors")


# License
st.markdown('''
---
## QuantUniversity License

© QuantUniversity 2025  
This notebook was created for **educational purposes only** and is **not intended for commercial use**.  

- You **may not copy, share, or redistribute** this notebook **without explicit permission** from QuantUniversity.  
- You **may not delete or modify this license cell** without authorization.  
- This notebook was generated using **QuCreate**, an AI-powered assistant.  
- Content generated by AI may contain **hallucinated or incorrect information**. Please **verify before using**.  

All rights reserved. For permissions or commercial licensing, contact: [info@quantuniversity.com](mailto:info@quantuniversity.com)
''')
